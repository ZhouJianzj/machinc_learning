{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "x,y = data.data, data.target\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=42,test_size=0.2)\n",
    "\n",
    "# 演示XGBoost\n",
    "\n",
    "# 将数据转换为 DMatrix 格式，这是 XGBoost 要求的格式\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "# 设置参数\n",
    "# max_depth: 这个参数指定了每棵树的最大深度。增大这个值会使模型更复杂，可以更好地拟合训练数据，但也更容易过拟合。通常来说，max_depth 的取值范围是 [1, ∞]。如果设置为 None，树的深度将不受限制。\n",
    "# eta（也称为 learning rate）: 学习率控制每次迭代中的权重更新幅度。它的作用是减小每棵树的贡献，使得模型更加稳定。较小的学习率通常需要更多的迭代次数来达到相同的效果。通常来说，eta 的取值范围是 (0, 1]。\n",
    "# objective: 这个参数指定了要优化的损失函数。对于多类别分类问题，可以选择 'multi:softmax'。此外，你还可以根据需要选择其他的目标函数，比如 'binary:logistic'（二分类逻辑回归）或 'reg:squarederror'（回归问题的平方损失函数）等。\n",
    "# num_class: 这个参数指定了类别的数量。在多类别分类问题中，需要设置 num_class 的值为类别的数量。例如，对于三类分类问题，可以设置 num_class=3。#\n",
    "# 综上所述，max_depth 和 eta 是控制模型复杂度和训练速度的两个重要参数，objective 用于指定优化的损失函数，而 num_class 则用于指定类别的数量。\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3\n",
    "}\n",
    "\n",
    "# 训练模型\n",
    "num_rounds = 100\n",
    "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"XGBoost Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-d6d2fd5a",
   "language": "python",
   "display_name": "PyCharm (pythonBase)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}